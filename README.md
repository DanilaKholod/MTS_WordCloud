# Nuclear IT Hack 2024
Задача  **"МТС Линк. Использование ИИ в продукте"**
## Состав команды WISH NYA
1. Холод Данила - python-разработчик, ML-разработчик
2. Кондратьев Матвей - NLP-разработчик
3. Мельников Вадим - python-разработчик
4. Китаев Степан - NLP-разработчик
## Описание задачи
При проведении опросов важно не только собрать ответы, но и качественно проанализировать их, чтобы понять реальные мотивы ипредпочтения людей.
Представим, чтосотрудники отвечают на вопрос: **«Что мотивирует вас работать больше?»**

Ответы могут быть самыми разными: _«команда»_, _«коллеги»_, _«зарплата»_, _«бабосики»_, _«шеф»_, _«атмосфера»_,_«амбициозные задачи»_ и т.д. Сырые данные зачастую избыточны и включают множество синонимов, просторечий или даже нецензурной лексики
## Задача
Разработать систему на основе ИИ, которая анализирует список пользовательских ответов возвращает понятное и интерпретируемое облако слов.
## Описание решения
```
├── model.py - Модели NLP с препроцессингом, токенизациеЙ, векторизацией и кластеризацией отзывов
├── mts_bot.py - Чат-бот, который использует разработанную модель и строит облако слов
└── data - Сгенерированные ChatGPT отзывы, которые использовались для тестов
```
Целью данного проекта является создание модели для кластеризации текстовых данных отзывов с использованием методов обработки естественного языка (NLP). Мы стремимся разделить отзывы на группы по ключевым темам-причинам, которые мотивируют работников. Задача представляет собой кластеризацию усреднённых ембеддингов строк в многомерном пространстве, с последующим называнием кластера наиболее репрезентативным словом.

Целевое слово выбрано как **самое частотное**.

### 1. Входные данные
Датасет представляет собой CSV-файл состоящий из строк (3-12 слов) размером около 2000 записей.

### 2. Препроцессинг
Была произведена стандартная подготовка данных. На препроцессинге слова были приведены к нижнему регистру, были убраны числовые символы, знаки пунктуации и стоп-слова. Также произведена токенизация полученных отзывов.

### 3. Векторизация
Векторизация предложений произведена с помощью усреднённых эмбеддингов слов с помощью модуля Navec, который предоставляет удобные и лёгкие эмбеддинги русских слов, что было оптимальным решением для нашей задачи. 

### 4. Кластеризация
Для кластеризации была выбрана модель DBSCAN, которая кластеризует объекты на основе плотностей распределения их в многомерном пространстве, а также хорошо определяет аномалии. Для оптимального параметра расстояния eps проведена кластеризация методом как средних для того же значения параметра К, что и в DBSCAN. Построен график дистанции между классами от количества объединённых классов, значение eps - координата по оси У точки излома графика. После этого было было выбрано самое частотное слово.

### 5. Потенциальные улучшения
Потенциальные направления для улучшения:
- Попробовать другие алгоритмы кластеризации (например  Agglomerative Clustering)
- Увеличить размер данных
- Использовать более продвинутые методы векторизации, такие как FastText или BERT
## Результаты
[Чат-бот](https://t.me/MTS_Word_Bot) в Telegram для загрузки в него файла csv с отзывами сотрудников, который на основе обученной ИИ модели генерирует облако слов.
## Ресурсы
- Документация по [scikit-learn](https://scikit-learn.org/)
- Статья о TF-IDF: [TF-IDF Explanation](https://en.wikipedia.org/wiki/Tf–idf)
- Библиотека Наташа, обработка естественного языка на примере шоу ЧТО БЫЛО ДАЛЬШЕ: [YouTube](https://www.youtube.com/watch?v=cGrreUMhOk4)
- Ссылка с русскими эмбедингами НАТАША: [GitHub](https://github.com/natasha/navec)
